{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import LongTensor\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = ['long_str',  # len = 8\n",
    "        'tiny',      # len = 4\n",
    "        'medium']    # len = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['<pad>'] + sorted(set([char for seq in seqs for char in seq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 9, 8, 4, 1, 11, 12, 10], [12, 5, 8, 14], [7, 3, 2, 5, 13, 7]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_seqs = [[vocab.index(tok) for tok in seq]for seq in seqs]\n",
    "vectorized_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(len(vocab), 4) # embedding_dim = 4\n",
    "lstm = LSTM(input_size=4, hidden_size=5, batch_first=True) # input_dim = 4, hidden_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  9.,  8.,  4.,  1., 11., 12., 10.],\n",
       "        [12.,  5.,  8., 14.,  0.,  0.,  0.,  0.],\n",
       "        [ 7.,  3.,  2.,  5., 13.,  7.,  0.,  0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_seqs_t = [torch.Tensor([vocab.index(tok) for tok in seq]) for seq in seqs]\n",
    "#vectorized_seqs_t\n",
    "seq_tensor_t=pad_sequence(vectorized_seqs_t,batch_first=True)\n",
    "seq_tensor_t\n",
    "#embedded_seq_tensor_t = embed(seq_tensor_t)\n",
    "#packed_input_t = pack_padded_sequence(embedded_seq_tensor_t, np.array([8,4,6]), batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 4, 6])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  9,  8,  4,  1, 11, 12, 10],\n",
       "        [12,  5,  8, 14,  0,  0,  0,  0],\n",
       "        [ 7,  3,  2,  5, 13,  7,  0,  0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  9,  8,  4,  1, 11, 12, 10],\n",
       "        [ 7,  3,  2,  5, 13,  7,  0,  0],\n",
       "        [12,  5,  8, 14,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0641,  0.9109, -0.9087,  0.3410],\n",
       "         [ 0.4785,  0.5911,  0.1120,  0.0364],\n",
       "         [ 0.5495, -0.0577, -0.5352, -1.0014],\n",
       "         [ 1.0056, -1.4505, -0.7981, -0.3690],\n",
       "         [-0.5623,  1.1768, -1.8777, -1.0699],\n",
       "         [-1.2558, -2.5015, -0.0727,  0.5966],\n",
       "         [-1.5572, -1.9498, -0.0357,  0.0061],\n",
       "         [-0.9151,  0.8572, -0.0613,  1.1927]],\n",
       "\n",
       "        [[-0.4312,  0.4526, -0.9976, -0.9833],\n",
       "         [-1.7393,  0.4898,  0.1344, -0.2936],\n",
       "         [-1.4355,  0.2238, -0.5792, -1.1298],\n",
       "         [ 0.8304, -0.4705, -0.5836,  0.3855],\n",
       "         [-0.7402,  1.5710, -0.8247, -0.6009],\n",
       "         [-0.4312,  0.4526, -0.9976, -0.9833],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824]],\n",
       "\n",
       "        [[-1.5572, -1.9498, -0.0357,  0.0061],\n",
       "         [ 0.8304, -0.4705, -0.5836,  0.3855],\n",
       "         [ 0.5495, -0.0577, -0.5352, -1.0014],\n",
       "         [-0.2883,  1.3329, -0.9172, -1.6868],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824],\n",
       "         [-0.2549, -1.2754, -0.3007,  1.1824]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_seq_tensor = embed(seq_tensor)\n",
    "embedded_seq_tensor\n",
    "#embedded_seq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0641,  0.9109, -0.9087,  0.3410],\n",
       "        [-0.4312,  0.4526, -0.9976, -0.9833],\n",
       "        [-1.5572, -1.9498, -0.0357,  0.0061],\n",
       "        [ 0.4785,  0.5911,  0.1120,  0.0364],\n",
       "        [-1.7393,  0.4898,  0.1344, -0.2936],\n",
       "        [ 0.8304, -0.4705, -0.5836,  0.3855],\n",
       "        [ 0.5495, -0.0577, -0.5352, -1.0014],\n",
       "        [-1.4355,  0.2238, -0.5792, -1.1298],\n",
       "        [ 0.5495, -0.0577, -0.5352, -1.0014],\n",
       "        [ 1.0056, -1.4505, -0.7981, -0.3690],\n",
       "        [ 0.8304, -0.4705, -0.5836,  0.3855],\n",
       "        [-0.2883,  1.3329, -0.9172, -1.6868],\n",
       "        [-0.5623,  1.1768, -1.8777, -1.0699],\n",
       "        [-0.7402,  1.5710, -0.8247, -0.6009],\n",
       "        [-1.2558, -2.5015, -0.0727,  0.5966],\n",
       "        [-0.4312,  0.4526, -0.9976, -0.9833],\n",
       "        [-1.5572, -1.9498, -0.0357,  0.0061],\n",
       "        [-0.9151,  0.8572, -0.0613,  1.1927]],\n",
       "       grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input = pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
    "packed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_output, (ht, ct) = lstm(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, input_sizes = pad_packed_sequence(packed_output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 6, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2006,  0.1382,  0.0585, -0.1302,  0.0500],\n",
       "         [ 0.1740,  0.0941,  0.1232, -0.2105,  0.1127],\n",
       "         [ 0.1037,  0.0493,  0.1047, -0.4676,  0.1194],\n",
       "         [-0.0187,  0.0871, -0.0560, -0.5884,  0.1054],\n",
       "         [ 0.3081,  0.1872,  0.0327, -0.6560,  0.1076],\n",
       "         [ 0.0388,  0.1274,  0.1071, -0.3349,  0.3023],\n",
       "         [ 0.0344,  0.1551,  0.1896, -0.1020,  0.4512],\n",
       "         [ 0.3019,  0.2200,  0.1950,  0.0981,  0.3258]],\n",
       "\n",
       "        [[ 0.1591,  0.0360,  0.0780, -0.3081,  0.0786],\n",
       "         [ 0.3399, -0.0783,  0.1871,  0.0289,  0.2781],\n",
       "         [ 0.3705, -0.0738,  0.1806,  0.0538,  0.3511],\n",
       "         [ 0.0824,  0.0746,  0.1143, -0.0474,  0.1796],\n",
       "         [ 0.4045,  0.1213,  0.1057, -0.1597,  0.2097],\n",
       "         [ 0.2996,  0.0975,  0.1260, -0.3423,  0.2200],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0175,  0.0406,  0.1812,  0.1457,  0.2247],\n",
       "         [-0.0379,  0.1187,  0.0389, -0.0332,  0.1222],\n",
       "         [ 0.0067,  0.1109,  0.0514, -0.3755,  0.1235],\n",
       "         [ 0.2823, -0.0844,  0.0716, -0.5676,  0.1308],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3019,  0.2200,  0.1950,  0.0981,  0.3258],\n",
       "         [ 0.2996,  0.0975,  0.1260, -0.3423,  0.2200],\n",
       "         [ 0.2823, -0.0844,  0.0716, -0.5676,  0.1308]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5474,  0.4745,  0.4630,  0.2259,  1.1334],\n",
       "         [ 0.5341,  0.2016,  0.2938, -0.5261,  0.4660],\n",
       "         [ 0.4441, -0.1284,  0.1968, -0.9596,  0.2366]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "a=[10,100,1000,10000]\n",
    "for i in range(1,len(a),1):\n",
    "    print(a[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
